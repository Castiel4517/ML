import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import precision_score, recall_score, f1_score

# æœºå™¨å­¦ä¹ æ¨¡å‹
from sklearn.linear_model import LogisticRegression, Ridge, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \
    ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
#mlines

import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']  # æ˜¾ç¤ºä¸­æ–‡
pd.set_option('display.max_columns', None)  # æ˜¾ç¤ºæ‰€æœ‰åˆ—
pd.set_option('display.max_rows', None)     # æ˜¾ç¤ºæ‰€æœ‰è¡Œ

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

print("=" * 80)
print("æœºå™¨å­¦ä¹ å®Œæ•´Pipeline: EDA â†’ é¢„å¤„ç† â†’ æ¨¡å‹å¯¹æ¯” â†’ æœ€ä¼˜é€‰æ‹©")
print("=" * 80)
      
# 1. æ•°æ®åŠ è½½å’Œå‡†å¤‡
print("\n1. æ•°æ®åŠ è½½å’Œå‡†å¤‡")
print("-" * 50)

# è¯»å–æ•°æ®

data = pd.read_csv(r'D:\20251018ML\1023ML\1018.csv')


print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(data.columns)
# å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
feature_cols = list(data.columns[:-1])

#gradeç›®æ ‡å˜é‡
main_target = data.columns[-1]
print(f"ç‰¹å¾å˜é‡: {feature_cols}")
print(f"ç›®æ ‡å˜é‡: {main_target}")

# ==================== EDAæ¢ç´¢æ€§æ•°æ®åˆ†æéƒ¨åˆ† ====================
print("\n" + "=" * 80)
print("EDA æ¢ç´¢æ€§æ•°æ®åˆ†æ")
print("=" * 80)

# 2. æ•°æ®æ¦‚è§ˆ
print("\n2. æ•°æ®åŸºæœ¬ä¿¡æ¯")
print("-" * 50)

print("æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
print(f"æ ·æœ¬æ•°é‡: {len(data)}")

# æ•°æ®ç±»å‹å’Œç¼ºå¤±å€¼ä¿¡æ¯
print("\næ•°æ®ç±»å‹å’Œç¼ºå¤±å€¼:")
info_df = pd.DataFrame({
'æ•°æ®ç±»å‹': data[feature_cols + [main_target]].dtypes,
'ç¼ºå¤±å€¼æ•°é‡': data[feature_cols + [main_target]].isnull().sum(),
'ç¼ºå¤±å€¼æ¯”ä¾‹(%)': (data[feature_cols + [main_target]].isnull().sum() / len(data) * 100).round(2),
'å”¯ä¸€å€¼æ•°é‡': data[feature_cols + [main_target]].nunique()
})
print(info_df)

# åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
print("\nç‰¹å¾å˜é‡æè¿°æ€§ç»Ÿè®¡:")
desc_stats = data[feature_cols].describe()
print(desc_stats.round(4))

# 3. ç›®æ ‡å˜é‡åˆ†æ
print("\n3. ç›®æ ‡å˜é‡åˆ†æ")
print("-" * 50)

# ç›®æ ‡å˜é‡åˆ†å¸ƒ
target_counts = data[main_target].value_counts()
target_props = data[main_target].value_counts(normalize=True)

print("ç›®æ ‡å˜é‡åˆ†å¸ƒ:")
target_summary = pd.DataFrame({
'æ•°é‡': target_counts,
'æ¯”ä¾‹(%)': (target_props * 100).round(2)
})
print(target_summary)

# ç›®æ ‡å˜é‡å¯è§†åŒ–
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# æŸ±çŠ¶å›¾
axes[0].bar(target_counts.index, target_counts.values)
axes[0].set_title(f'{main_target} åˆ†å¸ƒ')
axes[0].set_xlabel('ç±»åˆ«')
axes[0].set_ylabel('æ ·æœ¬æ•°é‡')
for i, v in enumerate(target_counts.values):
    axes[0].text(i, v + 0.5, str(v), ha='center', va='bottom')

# é¥¼å›¾
axes[1].pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%', startangle=90)
axes[1].set_title(f'{main_target} æ¯”ä¾‹åˆ†å¸ƒ')
# ç®±çº¿å›¾
sns.boxplot(x=data[main_target], y=data[feature_cols[0]], ax=axes[2])
axes[2].set_title(f'{feature_cols[0]} vs {main_target} ç®±çº¿å›¾')
axes[2].set_xlabel(main_target)
axes[2].set_ylabel(feature_cols[0])
plt.tight_layout()
plt.savefig('target_variable_analysis.png', dpi=300)
 #plt.show()

# 4. ç‰¹å¾å˜é‡åˆ†å¸ƒåˆ†æ
print("\n4. ç‰¹å¾å˜é‡åˆ†å¸ƒåˆ†æ")
print("-" * 50)

# è®¡ç®—éœ€è¦çš„å­å›¾æ•°é‡
n_features = len(feature_cols)
n_cols = 4
n_rows = (n_features + n_cols - 1) // n_cols

# ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
print("ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾...")
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))

# ä¿è¯ axes ä¸€ç»´åŒ–
if n_rows > 1 or n_cols > 1:
    axes = axes.ravel()
else:
    axes = [axes]

for i, col in enumerate(feature_cols):
    if i < len(axes):
        # ç›´æ–¹å›¾
        axes[i].hist(data[col].dropna(), bins=30, density=True,
                     alpha=0.7, edgecolor='black')

        # æ·»åŠ  KDE æ›²çº¿
        try:
            data[col].dropna().plot.density(ax=axes[i], linewidth=2)
        except Exception:
            pass

        axes[i].set_title(f'{col} åˆ†å¸ƒ')
        axes[i].set_xlabel(col)
        axes[i].set_ylabel('å¯†åº¦')
        axes[i].grid(True, alpha=0.3)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_val = data[col].mean()
        median_val = data[col].median()
        axes[i].axvline(mean_val, linestyle='--', alpha=0.7,
                        label=f'å‡å€¼: {mean_val:.2f}')
        axes[i].axvline(median_val, linestyle='--', alpha=0.7,
                        label=f'ä¸­ä½æ•°: {median_val:.2f}')
        axes[i].legend(fontsize=8)

# éšè—å¤šä½™çš„å­å›¾
for j in range(i + 1, len(axes)):
    axes[j].set_visible(False)

plt.tight_layout()
plt.savefig('feature_distribution_analysis.png', dpi=300)
 #plt.show()

# 5. ç®±çº¿å›¾åˆ†æ
print("\n5. ç®±çº¿å›¾åˆ†æï¼ˆå¼‚å¸¸å€¼æ£€æµ‹ï¼‰")
print("-" * 50)

print("ç»˜åˆ¶ç®±çº¿å›¾åˆ†æå¼‚å¸¸å€¼...")
fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))

# å±•å¹³ axes ä¸ºä¸€ç»´
if n_rows > 1 or n_cols > 1:
    axes = axes.ravel()
else:
    axes = [axes]

outlier_summary = {}

for i, col in enumerate(feature_cols):
    if i < len(axes):
        # ç®±çº¿å›¾
        box_plot = axes[i].boxplot(data[col].dropna(), patch_artist=True)
        box_plot['boxes'][0].set_facecolor('lightblue')

        axes[i].set_title(f'{col} ç®±çº¿å›¾')
        axes[i].set_ylabel(col)
        axes[i].grid(True, alpha=0.3)

        # è®¡ç®—å¼‚å¸¸å€¼
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)][col]
        outlier_count = len(outliers)
        outlier_percent = (outlier_count / len(data)) * 100

        outlier_summary[col] = {
            'count': outlier_count,
            'percentage': outlier_percent,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound
        }

        # æ·»åŠ å¼‚å¸¸å€¼ä¿¡æ¯
        axes[i].text(
            0.02, 0.98,
            f'å¼‚å¸¸å€¼: {outlier_count} ({outlier_percent:.1f}%)',
            transform=axes[i].transAxes,
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5)
        )

# éšè—å¤šä½™çš„å­å›¾
for j in range(i + 1, len(axes)):
    axes[j].set_visible(False)

plt.tight_layout()
plt.savefig('boxplot_outlier_analysis.png', dpi=300)
 #plt.show()

# å¼‚å¸¸å€¼ç»Ÿè®¡
print("\nå¼‚å¸¸å€¼ç»Ÿè®¡æ€»ç»“:")
outlier_df = pd.DataFrame(outlier_summary).T
outlier_df.columns = ['å¼‚å¸¸å€¼æ•°é‡', 'å¼‚å¸¸å€¼æ¯”ä¾‹(%)', 'ä¸‹ç•Œ', 'ä¸Šç•Œ']
outlier_df['å¼‚å¸¸å€¼æ¯”ä¾‹(%)'] = outlier_df['å¼‚å¸¸å€¼æ¯”ä¾‹(%)'].round(2)
print(outlier_df)


# 6. ç‰¹å¾ç›¸å…³æ€§åˆ†æ
print("\n6. ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
print("-" * 50)

print("è®¡ç®—ç‰¹å¾é—´ç›¸å…³æ€§...")
correlation_matrix = data[feature_cols].corr()

# ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(
    correlation_matrix,
    mask=mask,
    annot=True,
    cmap='coolwarm',
    center=0,
    square=True,
    linewidths=0.5,
    cbar_kws={"shrink": 0.5},
    fmt='.3f'
)
plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
plt.tight_layout()
plt.savefig('feature_correlation_matrix.png', dpi=300)
 #plt.show()

# é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
print("\né«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|r| > 0.8):")
high_corr_pairs = []

for i in range(len(correlation_matrix.columns)):
    for j in range(i + 1, len(correlation_matrix.columns)):
        corr_val = correlation_matrix.iloc[i, j]
        if abs(corr_val) > 0.8:
            high_corr_pairs.append({
                'feature1': correlation_matrix.columns[i],
                'feature2': correlation_matrix.columns[j],
                'correlation': corr_val
            })

if high_corr_pairs:
    high_corr_df = pd.DataFrame(high_corr_pairs)
    high_corr_df = high_corr_df.sort_values('correlation', key=abs, ascending=False)
    print(high_corr_df)
else:
    print("æ²¡æœ‰å‘ç°é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹")

# è‹¥æœ‰é«˜ç›¸å…³ç‰¹å¾ï¼Œåˆ™å¯¹é«˜ç›¸å…³ç‰¹å¾è¿›è¡Œå¤„ç†
if high_corr_pairs:
    to_remove = set()
    for pair in high_corr_pairs:
        # ç®€å•ç­–ç•¥ï¼šç§»é™¤ç›¸å…³æ€§è¾ƒé«˜å¯¹ä¸­çš„ç¬¬äºŒä¸ªç‰¹å¾
        to_remove.add(pair['feature2'])
    print(f"\nå»ºè®®ç§»é™¤ä»¥ä¸‹é«˜ç›¸å…³æ€§ç‰¹å¾ä»¥å‡å°‘å¤šé‡å…±çº¿æ€§: {to_remove}")
    feature_cols = [col for col in feature_cols if col not in to_remove]
    print(f"æ›´æ–°åçš„ç‰¹å¾åˆ—è¡¨: {feature_cols}")
else:
    print("æ— éœ€ç§»é™¤ä»»ä½•ç‰¹å¾")


# 7. ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³ç³»åˆ†æ
print("\n7. ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³ç³»åˆ†æ")
print("-" * 50)

# ä¸åŒç±»åˆ«ä¸‹çš„ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”
unique_targets = data[main_target].unique()
n_targets = len(unique_targets)

print(f"ç»˜åˆ¶ä¸åŒ {main_target} ç±»åˆ«ä¸‹çš„ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”...")

# ä¸ºæ¯ä¸ªç‰¹å¾åˆ›å»ºåˆ†ç±»å¯¹æ¯”å›¾
for idx, col in enumerate(feature_cols[:6]):  # åªæ˜¾ç¤ºå‰6ä¸ªç‰¹å¾é¿å…å›¾å¤ªå¤š
    plt.figure(figsize=(15, 5))

    # å°æç´å›¾
    plt.subplot(1, 3, 1)
    sns.violinplot(data=data, x=main_target, y=col)
    plt.title(f'{col} - å°æç´å›¾')
    plt.xticks(rotation=45)

    # ç®±çº¿å›¾
    plt.subplot(1, 3, 2)
    sns.boxplot(data=data, x=main_target, y=col)
    plt.title(f'{col} - ç®±çº¿å›¾å¯¹æ¯”')
    plt.xticks(rotation=45)

    # ç›´æ–¹å›¾å åŠ 
    plt.subplot(1, 3, 3)
    for target in unique_targets:
        subset = data[data[main_target] == target][col].dropna()
        plt.hist(subset, alpha=0.6, label=f'{target} (n={len(subset)})', bins=20)
    plt.xlabel(col)
    plt.ylabel('é¢‘æ¬¡')
    plt.title(f'{col} - åˆ†å¸ƒå¯¹æ¯”')
    plt.legend()

    plt.tight_layout()
    plt.savefig(f'feature_{col}_by_{main_target}.png', dpi=300)
     #plt.show()

# 8. ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§
print("\n8. ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§")
print("-" * 50)

# è‡ªåŠ¨åˆ¤æ–­ç›®æ ‡å˜é‡ç±»å‹ï¼šè‹¥ä¸ºæ•°å€¼å‹ä¸”å”¯ä¸€å€¼å¤š -> å›å½’ç›¸å…³æ€§ï¼›å¦åˆ™ -> åˆ†ç±»æ–¹å·®åˆ†æ
is_numeric = data[main_target].dtype in ['int64', 'float64']
is_classification = (not is_numeric) or (len(unique_targets) <= 10)

if is_numeric and not is_classification:
    # æ•°å€¼å‹ç›®æ ‡å˜é‡ï¼šè®¡ç®— Pearson ç›¸å…³æ€§
    target_correlation = (
        data[feature_cols + [main_target]]
        .corr()[main_target]
        .drop(main_target)
        .sort_values(key=abs, ascending=False)
    )

    print("ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§:")
    print(target_correlation)

    # å¯è§†åŒ–ç‰¹å¾ä¸ç›®æ ‡å˜é‡ç›¸å…³æ€§
    plt.figure(figsize=(10, 8))
    target_correlation.plot(kind='barh')
    plt.title(f'ç‰¹å¾ä¸ {main_target} çš„ç›¸å…³æ€§')
    plt.xlabel('ç›¸å…³ç³»æ•°')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(f'feature_target_correlation_{main_target}.png', dpi=300)
     #plt.show()

else:
    # åˆ†ç±»å˜é‡ç›®æ ‡ï¼šä½¿ç”¨æ–¹å·®åˆ†æ ANOVA
    from scipy import stats

    print("ç‰¹å¾ä¸ç›®æ ‡å˜é‡å…³è”æ€§åˆ†æ (F-ç»Ÿè®¡é‡):")
    f_stats = []
    p_values = []

    for col in feature_cols:
        groups = [data[data[main_target] == target][col].dropna() for target in unique_targets]
        # è·³è¿‡ç±»åˆ«æ ·æœ¬è¿‡å°‘çš„æƒ…å†µ
        if any(len(g) < 2 for g in groups):
            f_stats.append(np.nan)
            p_values.append(np.nan)
            continue
        f_stat, p_val = stats.f_oneway(*groups)
        f_stats.append(f_stat)
        p_values.append(p_val)

    anova_results = pd.DataFrame({
        'Feature': feature_cols,
        'F_statistic': f_stats,
        'p_value': p_values,
        'significant': ['æ˜¯' if p < 0.05 else 'å¦' for p in p_values]
    }).sort_values('F_statistic', ascending=False)

    print(anova_results)

# ==================== é¢„å¤„ç†å’Œå»ºæ¨¡éƒ¨åˆ† ====================

# 2. æ•°æ®é¢„å¤„ç†
print("\n" + "=" * 80)
print("æ•°æ®é¢„å¤„ç†")
print("=" * 80)

# æå–ç‰¹å¾å’Œç›®æ ‡
X = data[feature_cols].copy()
y = data[main_target].copy()

# å¤„ç†ç¼ºå¤±å€¼
print("å¤„ç†ç¼ºå¤±å€¼...")
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median')
X_filled = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

print(f"å¤„ç†å‰ç¼ºå¤±å€¼: {X.isnull().sum().sum()}")
print(f"å¤„ç†åç¼ºå¤±å€¼: {X_filled.isnull().sum().sum()}")

# 3. å¼‚å¸¸å€¼å¤„ç†
print("\n3. å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†")
print("-" * 50)


def detect_outliers_iqr(df, column):
    """ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = (df[column] < lower_bound) | (df[column] > upper_bound)
    return outliers, lower_bound, upper_bound


# æ£€æµ‹å¼‚å¸¸å€¼
outlier_info = {}
total_outliers = pd.Series([False] * len(X_filled))

for col in feature_cols:
    outliers, lower, upper = detect_outliers_iqr(X_filled, col)
    outlier_count = outliers.sum()
    outlier_percent = (outlier_count / len(X_filled)) * 100

    outlier_info[col] = {
        'count': outlier_count,
        'percentage': outlier_percent,
        'lower_bound': lower,
        'upper_bound': upper
    }

    total_outliers = total_outliers | outliers

print("å¼‚å¸¸å€¼ç»Ÿè®¡:")
for col, info in outlier_info.items():
    print(f"{col}: {info['count']} ({info['percentage']:.2f}%)")

print(f"\næ€»å¼‚å¸¸å€¼æ ·æœ¬æ•°: {total_outliers.sum()} ({(total_outliers.sum() / len(X_filled)) * 100:.2f}%)")

# å¼‚å¸¸å€¼å¤„ç†ç­–ç•¥
outlier_threshold = 0.05  # 5%é˜ˆå€¼
if (total_outliers.sum() / len(X_filled)) > outlier_threshold:
    print("\nå¼‚å¸¸å€¼æ¯”ä¾‹è¾ƒé«˜ï¼Œä½¿ç”¨Winsorizingæ–¹æ³•å¤„ç†...")
    # Winsorizing: å°†å¼‚å¸¸å€¼æ›¿æ¢ä¸ºåˆ†ä½æ•°å€¼
    X_clean = X_filled.copy()
    y_clean = y.copy()  # ä¿è¯ y ä¸ X_clean å¯¹é½
    for col in feature_cols:
        outliers, lower, upper = detect_outliers_iqr(X_filled, col)
        X_clean.loc[X_clean[col] < lower, col] = lower
        X_clean.loc[X_clean[col] > upper, col] = upper
else:
    print("\nå¼‚å¸¸å€¼æ¯”ä¾‹è¾ƒä½ï¼Œç›´æ¥ç§»é™¤å¼‚å¸¸å€¼...")
    # ç§»é™¤å¼‚å¸¸å€¼
    X_clean = X_filled[~total_outliers].copy()
    y_clean = y[~total_outliers].copy()

print(f"å¤„ç†åæ•°æ®å½¢çŠ¶: {X_clean.shape}")

# 4. æ•°æ®æ ‡å‡†åŒ–
print("\n4. æ•°æ®æ ‡å‡†åŒ–")
print("-" * 50)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X_clean), columns=X_clean.columns)

print("æ ‡å‡†åŒ–å‰åå¯¹æ¯”:")
comparison_df = pd.DataFrame({
    'åŸå§‹å‡å€¼': X_clean.mean(),
    'åŸå§‹æ ‡å‡†å·®': X_clean.std(),
    'æ ‡å‡†åŒ–åå‡å€¼': X_scaled.mean(),
    'æ ‡å‡†åŒ–åæ ‡å‡†å·®': X_scaled.std()
})
print(comparison_df.round(4))


# 5. PCAé™ç»´åˆ†æ
print("\n5. PCAé™ç»´åˆ†æ")
print("-" * 50)

from sklearn.decomposition import PCA

# æ‰§è¡ŒPCAåˆ†æ
pca_full = PCA()
pca_result = pca_full.fit_transform(X_scaled)

# è®¡ç®—ç´¯ç§¯è§£é‡Šæ–¹å·®
explained_variance = pca_full.explained_variance_ratio_
cumulative_variance = np.cumsum(explained_variance)

# å¯è§†åŒ–PCAç»“æœ
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# ä¸ªä½“è§£é‡Šæ–¹å·®
ax1.bar(range(1, len(explained_variance) + 1), explained_variance)
ax1.set_xlabel('ä¸»æˆåˆ†')
ax1.set_ylabel('è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax1.set_title('å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax1.grid(True, alpha=0.3)

# ç´¯ç§¯è§£é‡Šæ–¹å·®
ax2.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'bo-')
ax2.axhline(y=0.8, color='r', linestyle='--', label='80%')
ax2.axhline(y=0.9, color='g', linestyle='--', label='90%')
ax2.axhline(y=0.95, color='orange', linestyle='--', label='95%')
ax2.set_xlabel('ä¸»æˆåˆ†æ•°é‡')
ax2.set_ylabel('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax2.set_title('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('pca_variance_analysis.png', dpi=300)
 #plt.show()

# PCAé™ç»´å†³ç­–
n_features = len(feature_cols)
n_components_80 = np.where(cumulative_variance >= 0.8)[0][0] + 1
n_components_90 = np.where(cumulative_variance >= 0.9)[0][0] + 1
n_components_95 = np.where(cumulative_variance >= 0.95)[0][0] + 1

print(f"åŸå§‹ç‰¹å¾æ•°: {n_features}")
print(f"è§£é‡Š80%æ–¹å·®éœ€è¦: {n_components_80} ä¸ªä¸»æˆåˆ†")
print(f"è§£é‡Š90%æ–¹å·®éœ€è¦: {n_components_90} ä¸ªä¸»æˆåˆ†")
print(f"è§£é‡Š95%æ–¹å·®éœ€è¦: {n_components_95} ä¸ªä¸»æˆåˆ†")

# é™ç»´å†³ç­–
use_pca = False
if n_features > 10 and n_components_90 < n_features * 0.7:
    use_pca = True
    optimal_components = n_components_90
    print(f"\nâœ“ å»ºè®®ä½¿ç”¨PCAé™ç»´ï¼Œä¿ç•™{optimal_components}ä¸ªä¸»æˆåˆ†")
    
    pca = PCA(n_components=optimal_components)
    X_final = pd.DataFrame(
        pca.fit_transform(X_scaled),
        columns=[f'PC{i + 1}' for i in range(optimal_components)]
    )
else:
    print(f"\nâœ“ ä¸å»ºè®®ä½¿ç”¨PCAé™ç»´ï¼Œä¿æŒåŸå§‹ç‰¹å¾")
    X_final = X_scaled

print(f"æœ€ç»ˆç‰¹å¾ç»´åº¦: {X_final.shape}")


# 6. æ•°æ®é›†åˆ’åˆ†
print("\n6. æ•°æ®é›†åˆ’åˆ†")
print("-" * 50)

# ç¡®ä¿ X_final å’Œ y_final å®šä¹‰ä¸€è‡´
if 'X_clean' in locals() and 'y_clean' in locals():
    X_final = X_clean
    y_final = y_clean
else:
    X_final = X
    y_final = y

# ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç¡®ä¿ç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼Œç„¶åå†è¿›è¡Œåˆ’åˆ†
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_final,
    y_final,
    test_size=0.2,
    random_state=42,
    stratify=y_final
)

# âœ… é”å®šå‰¯æœ¬ï¼Œé˜²æ­¢åç»­è¢«è¦†ç›–
X_train_main, X_test_main = X_train.copy(), X_test.copy()
y_train_main, y_test_main = y_train.copy(), y_test.copy()

print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
print(f"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y_train).value_counts().to_dict()}")
print(f"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y_test).value_counts().to_dict()}")


# 7. æœºå™¨å­¦ä¹ æ¨¡å‹å®šä¹‰
print("\n7. æœºå™¨å­¦ä¹ æ¨¡å‹å®šä¹‰")
print("-" * 50)

from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# å®šä¹‰13ç§æœºå™¨å­¦ä¹ æ¨¡å‹
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'SGD Classifier': SGDClassifier(loss='log_loss',max_iter=1000, tol=1e-3),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(n_estimators=100),
    'AdaBoost': AdaBoostClassifier(n_estimators=100),
    'Extra Trees': ExtraTreesClassifier(n_estimators=100),
    'Support Vector Machine': SVC(probability=True),
    'Gaussian Naive Bayes': GaussianNB(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Multi-layer Perceptron': MLPClassifier(max_iter=1000),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    'lightGBM': LGBMClassifier()
}

print(f"å®šä¹‰äº†{len(models)}ç§æœºå™¨å­¦ä¹ æ¨¡å‹")

# 8. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
print("\n8. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°")
print("-" * 50)

# å­˜å‚¨ç»“æœ
results = {}
cv_scores = {}
predictions = {}

# 5æŠ˜äº¤å‰éªŒè¯
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹...")
for name, model in models.items():
    print(f"è®­ç»ƒ {name}...", end=' ')

    try:
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train, y_train)

        # é¢„æµ‹
        y_pred = model.predict(X_test)
        if hasattr(model, 'predict_proba') and len(np.unique(y_final)) == 2:
            y_pred_proba = model.predict_proba(X_test)[:, 1]
        else:
            y_pred_proba = None

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')

        # äº¤å‰éªŒè¯
        cv_score = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')

        # å­˜å‚¨ç»“æœ
        results[name] = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'cv_mean': cv_score.mean(),
            'cv_std': cv_score.std()
        }

        cv_scores[name] = cv_score
        predictions[name] = {'y_pred': y_pred, 'y_pred_proba': y_pred_proba}

        print("âœ“")

    except Exception as e:
        print(f"âœ— é”™è¯¯: {str(e)}")
        continue


import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc, RocCurveDisplay
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ------------- 2. è®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼Œä¿å­˜åˆ†æ•° -------------------
print("\n=== æ¨¡å‹è®­ç»ƒå¹¶ç¼“å­˜é¢„æµ‹æ¦‚ç‡ ===")

y_test_bin = label_binarize(y_final, classes=sorted(y_final.unique()))
n_classes = y_test_bin.shape[1]

# é‡æ–°åˆ‡åˆ†ï¼ˆä¿æŒä¸å‰é¢ä¸€è‡´ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X_final, y_final, test_size=0.2, random_state=42, stratify=y_final)
y_test_bin = label_binarize(y_test, classes=sorted(y_final.unique()))


model_scores = {}  # å­˜AUC
model_fpr_tpr = {}  # å­˜æ›²çº¿ (fpr, tpr)
skip_models = []  # æ— æ³•ç”»ROCçš„æ¨¡å‹

for name, model in models.items():
    try:
        model.fit(X_train, y_train)

        # å–å¾—â€œè¿ç»­è¾“å‡ºâ€ä»¥ç»˜åˆ¶ ROC
        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(X_test)  # shape = (n_samples, n_classes)
        elif hasattr(model, "decision_function"):
            y_score = model.decision_function(X_test)
            # è‹¥ decision_function åªç»™ (n_samples,), è½¬æˆ (n_samples, n_classes)
            if y_score.ndim == 1:
                y_score = np.column_stack([-y_score, y_score])
        else:
            print(f"âš ï¸  {name} æ—¢æ—  predict_proba ä¹Ÿæ—  decision_functionï¼Œè·³è¿‡ ROCã€‚")
            skip_models.append(name)
            continue

        # è®¡ç®— micro-average & macro-average AUC
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        # micro
        fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())
        roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

        # macro
        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
        mean_tpr = np.zeros_like(all_fpr)
        for i in range(n_classes):
            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
        mean_tpr /= n_classes
        fpr["macro"] = all_fpr
        tpr["macro"] = mean_tpr
        roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

        model_scores[name] = roc_auc
        model_fpr_tpr[name] = (fpr, tpr)
        print(f"âœ“ {name} - macro AUC: {roc_auc['macro']:.3f}")

    except Exception as e:
        print(f"âœ— {name} è®­ç»ƒæˆ–é¢„æµ‹å‡ºé”™: {e}")
        skip_models.append(name)
        continue

# ------------- 3. ç»˜åˆ¶ä¸€å¼ å¤§å›¾ï¼šmacro-average ROC -----------------
print("\n=== ç»˜åˆ¶ ROC æ›²çº¿ ===")
plt.figure(figsize=(10, 8))
colors = cycle(plt.cm.tab20.colors)  # è‡³å°‘ 20 ç§é¢œè‰²

for (name, color) in zip(model_scores.keys(), colors):
    fpr, tpr = model_fpr_tpr[name]
    auc_val = model_scores[name]["macro"]
    plt.plot(
        fpr["macro"],
        tpr["macro"],
        color=color,
        lw=2,
        label=f"{name} (AUC = {auc_val:.3f})"
    )

# å¯¹è§’çº¿
plt.plot([0, 1], [0, 1], "k--", lw=1)

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.title("Macro-Average ROC Curves (3-class, 12 Models)", fontsize=14, fontweight="bold")
plt.legend(loc="lower right", fontsize=8)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("all_models_macro_roc.png", dpi=300)
 #plt.show()

# ------------- 4. ï¼ˆå¯é€‰ï¼‰å†ç”» micro-average -----------------
plt.figure(figsize=(10, 8))
colors = cycle(plt.cm.Dark2.colors)

for (name, color) in zip(model_scores.keys(), colors):
    fpr, tpr = model_fpr_tpr[name]
    auc_val = model_scores[name]["micro"]
    plt.plot(
        fpr["micro"],
        tpr["micro"],
        color=color,
        lw=2,
        label=f"{name} (AUC = {auc_val:.3f})"
    )

plt.plot([0, 1], [0, 1], "k--", lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate", fontsize=12)
plt.ylabel("True Positive Rate", fontsize=12)
plt.title("Micro-Average ROC Curves (3-class, 12 Models)", fontsize=14, fontweight="bold")
plt.legend(loc="lower right", fontsize=8)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("all_models_micro_roc.png", dpi=300)
 #plt.show()

# ------------- 5. ç®€å•æ±‡æ€»è¡¨ -----------------
print("\n=== ä¸»è¦ AUC æ±‡æ€» (macro / micro) ===")
for name, scores in model_scores.items():
    print(f"{name:25s}  Macro AUC: {scores['macro']:.3f}  |  Micro AUC: {scores['micro']:.3f}")

if skip_models:
    print("\nâš ï¸ ä»¥ä¸‹æ¨¡å‹å› ç¼ºå°‘è¿ç»­è¾“å‡ºè€Œæœªç»˜åˆ¶ ROCï¼š", ", ".join(skip_models))


# 9. ç»“æœå¯è§†åŒ–å¯¹æ¯”
print("\n9. æ¨¡å‹æ€§èƒ½å¯è§†åŒ–å¯¹æ¯”")
print("-" * 50)

# åˆ›å»ºç»“æœDataFrame
results_df = pd.DataFrame(results).T
print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨:")
print(results_df.round(4))

# æ€§èƒ½å¯¹æ¯”å¯è§†åŒ–
fig, axes = plt.subplots(2, 3, figsize=(20, 12))
axes = axes.ravel()

metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'cv_mean']
metric_names = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°', 'äº¤å‰éªŒè¯å‡å€¼']

for i, (metric, name) in enumerate(zip(metrics, metric_names)):
    if i < len(axes):
        data_to_plot = results_df[metric].sort_values(ascending=False)
        bars = axes[i].bar(range(len(data_to_plot)), data_to_plot.values, color='skyblue', alpha=0.8)
        axes[i].set_title(f'{name} å¯¹æ¯”')
        axes[i].set_xticks(range(len(data_to_plot)))
        axes[i].set_xticklabels(data_to_plot.index, rotation=45, ha='right')
        axes[i].set_ylabel(name)
        axes[i].grid(True, alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for j, bar in enumerate(bars):
            height = bar.get_height()
            axes[i].text(bar.get_x() + bar.get_width() / 2., height + 0.001,
                         f'{height:.3f}', ha='center', va='bottom', fontsize=8)

# äº¤å‰éªŒè¯åˆ†æ•°ç®±çº¿å›¾
if len(cv_scores) > 0:
    axes[5].boxplot([cv_scores[name] for name in results.keys()],
                    labels=[name for name in results.keys()])
    axes[5].set_title('äº¤å‰éªŒè¯åˆ†æ•°åˆ†å¸ƒ')
    axes[5].set_xticklabels(results.keys(), rotation=45, ha='right')
    axes[5].set_ylabel('å‡†ç¡®ç‡')
    axes[5].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('model_performance_comparison.png', dpi=300)
 #plt.show()


# 10. ç»¼åˆæ’åå’Œæœ€ä¼˜æ¨¡å‹é€‰æ‹©
print("\n10. ç»¼åˆæ’åå’Œæœ€ä¼˜æ¨¡å‹é€‰æ‹©")
print("-" * 50)

# è®¡ç®—ç»¼åˆå¾—åˆ†
weights = {
    'accuracy': 0.3,
    'precision': 0.2,
    'recall': 0.2,
    'f1_score': 0.2,
    'cv_mean': 0.1
}

results_df['ç»¼åˆå¾—åˆ†'] = 0
for metric, weight in weights.items():
    # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
    normalized = (results_df[metric] - results_df[metric].min()) / (results_df[metric].max() - results_df[metric].min())
    results_df['ç»¼åˆå¾—åˆ†'] += normalized * weight

# æ’åº
final_ranking = results_df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)

print("æœ€ç»ˆæ¨¡å‹æ’å:")
print("=" * 70)
ranking_display = final_ranking[['accuracy', 'precision', 'recall', 'f1_score', 'cv_mean', 'ç»¼åˆå¾—åˆ†']].round(4)

for i, (name, row) in enumerate(ranking_display.iterrows(), 1):
    print(f"{i:2d}. {name:15s} | ç»¼åˆå¾—åˆ†: {row['ç»¼åˆå¾—åˆ†']:.4f} | "
          f"å‡†ç¡®ç‡: {row['accuracy']:.4f} | F1: {row['f1_score']:.4f} | "
          f"CV: {final_ranking.loc[name, 'cv_mean']:.4f}Â±{final_ranking.loc[name, 'cv_std']:.4f}")

# é€‰æ‹©æœ€ä¼˜æ¨¡å‹
best_model_name = final_ranking.index[0]
best_model = models[best_model_name]
best_predictions = predictions[best_model_name]

print(f"\nğŸ† æœ€ä¼˜æ¨¡å‹: {best_model_name}")
print(f"   ç»¼åˆå¾—åˆ†: {final_ranking.iloc[0]['ç»¼åˆå¾—åˆ†']:.4f}")
print(f"   å‡†ç¡®ç‡: {final_ranking.iloc[0]['accuracy']:.4f}")
print(f"   F1åˆ†æ•°: {final_ranking.iloc[0]['f1_score']:.4f}")


# 11. æ¨¡å‹è¯¦ç»†åˆ†æ
print("\n11. æ¨¡å‹è¯¦ç»†åˆ†æ")
print("-" * 50)

# 12ç§æ¨¡å‹ä¸­çš„æ··æ·†çŸ©é˜µ
for name in results.keys():
    y_pred = predictions[name]['y_pred']
    y_pred_proba = predictions[name]['y_pred_proba']

    print(f"\nğŸ” {name} æ¨¡å‹è¯¦ç»†åˆ†æ")

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - æ··æ·†çŸ©é˜µ')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.tight_layout()
    plt.savefig(f'{name}_confusion_matrix.png', dpi=300)
     #plt.show()

print("\n" + "=" * 80)
print("ğŸ‰ å®Œæ•´çš„æœºå™¨å­¦ä¹ Pipelineå·²å®Œæˆ!")
print("ğŸ” åŒ…å«EDAåˆ†æ â†’ æ•°æ®é¢„å¤„ç† â†’ æ¨¡å‹å¯¹æ¯” â†’ ç»“æœåˆ†æ")
print("ğŸ“Š ç”Ÿæˆäº†è¯¦ç»†çš„å¯è§†åŒ–å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š")
print("=" * 80)

# æµ‹è¯•é›†é¢„æµ‹ç»“æœï¼Œè®¡ç®—å„ä¸ªç±»åˆ«æ¦‚ç‡
y_test_pred = best_model.predict(X_test)
y_test_pred_proba = best_model.predict_proba(X_test) if hasattr(best_model, 'predict_proba') else None

test_results_df = pd.DataFrame({
    'çœŸå®æ ‡ç­¾': y_test,
    'é¢„æµ‹æ ‡ç­¾': y_test_pred
})

if y_test_pred_proba is not None:
    for i in range(y_test_pred_proba.shape[1]):
        test_results_df[f'ç±»åˆ«_{i}_æ¦‚ç‡'] = y_test_pred_proba[:, i]

print("\næµ‹è¯•é›†é¢„æµ‹ç»“æœç¤ºä¾‹:")
print(test_results_df.head())


# SHAPå¯è§†åŒ– - ä½¿ç”¨LightGBMæ¨¡å‹
# è®­ç»ƒæ¨¡å‹
import shap
import lightgbm as lgb
import optuna
from sklearn.model_selection import cross_val_score
import numpy as np

# å®šä¹‰ç›®æ ‡å‡½æ•°
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'num_leaves': trial.suggest_int('num_leaves', 10, 100),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),
        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
        'random_state': 42,
        'n_jobs': -1,
        'verbose': -1
    }

    model = lgb.LGBMClassifier(**params)
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    return np.mean(scores)


print("å¼€å§‹è´å¶æ–¯ä¼˜åŒ–...")
# åˆ›å»ºstudyå¹¶ä¼˜åŒ–
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print(f"æœ€ä½³äº¤å‰éªŒè¯åˆ†æ•°: {study.best_value:.4f}")
print("æœ€ä½³å‚æ•°:")
for param, value in study.best_params.items():
    print(f"  {param}: {value}")

# ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
model = lgb.LGBMClassifier(**study.best_params, random_state=42, n_jobs=-1, verbose=-1)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
train_score = model.score(X_train, y_train)
test_score = model.score(X_test, y_test)

print(f"\nä½¿ç”¨ä¼˜åŒ–åå‚æ•°çš„ç»“æœ:")
print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.4f}")
print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.4f}")

# 1. è®¡ç®— SHAP å€¼
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# åˆ¤æ–­åˆ†ç±»ç±»å‹
if isinstance(shap_values, list) and len(shap_values) > 1:
    # å¤šåˆ†ç±»
    n_classes = len(shap_values)
    shap_values_list = shap_values
else:
    # äºŒåˆ†ç±»æˆ–å•è¾“å‡º
    n_classes = 2
    shap_values_list = [np.array(shap_values), np.array(shap_values)]  # ä¿è¯å…¼å®¹å¾ªç¯
    # å¦‚æœäºŒåˆ†ç±»ï¼Œé€šå¸¸é€‰æ‹©æ­£ç±» SHAP å€¼
    shap_values_list[1] = shap_values_list[0]

# class_names_display å·²å­˜åœ¨
if 'class_names_display' not in locals():
    class_names_display = [f'Class_{i}' for i in range(n_classes)]

# ==================== SHAP Bar Plot - ç»¼åˆç‰¹å¾é‡è¦æ€§ ====================
plt.figure(figsize=(12, 8))
shap.summary_plot(shap_values_list[1] if n_classes == 2 else shap_values_list[0],
                  X_test,
                  feature_names=feature_cols,
                  plot_type="bar",
                  class_names=class_names_display,
                  show=False)
plt.title('SHAP ç‰¹å¾é‡è¦æ€§æ’åº - LightGBM', fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.savefig('shap_bar_plot_lightgbm.png', dpi=300, bbox_inches='tight')
 #plt.show()

# ==================== SHAP Feature Importance by Class ====================
fig, axes = plt.subplots(1, n_classes, figsize=(6*n_classes, 6))
if n_classes == 1:
    axes = [axes]
colors = ['steelblue', 'coral', 'lightgreen', 'orange', 'purple']  # æ”¯æŒæœ€å¤š5ç±»

for i in range(n_classes):
    class_importance = np.mean(np.abs(shap_values_list[i]), axis=0)
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': class_importance
    }).sort_values('importance', ascending=True)

    axes[i].barh(importance_df['feature'], importance_df['importance'],
                 color=colors[i])
    axes[i].set_title(f'{class_names_display[i]}\nSHAPç‰¹å¾é‡è¦æ€§ - LightGBM',
                      fontsize=12, fontweight='bold')
    axes[i].set_xlabel('å¹³å‡|SHAPå€¼|')

plt.tight_layout()
plt.savefig('shap_importance_by_class_lightgbm.png', dpi=300, bbox_inches='tight')
 #plt.show()

# ==================== SHAP Overall Feature Importance ====================
overall_importance = np.mean([np.mean(np.abs(shap_values_list[i]), axis=0)
                              for i in range(n_classes)], axis=0)

importance_df = pd.DataFrame({
    'feature': feature_cols,
    'importance': overall_importance
}).sort_values('importance', ascending=True)

plt.figure(figsize=(10, 8))
bars = plt.barh(importance_df['feature'], importance_df['importance'],
                color='steelblue', alpha=0.8)
plt.title('SHAP ç»¼åˆç‰¹å¾é‡è¦æ€§ (æ‰€æœ‰ç±»åˆ«å¹³å‡) - LightGBM', fontsize=14, fontweight='bold', pad=20)
plt.xlabel('å¹³å‡|SHAPå€¼|')
plt.grid(axis='x', alpha=0.3)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, bar in enumerate(bars):
    width = bar.get_width()
    plt.text(width + width * 0.01, bar.get_y() + bar.get_height() / 2,
             f'{width:.3f}', ha='left', va='center', fontsize=10)

plt.tight_layout()
plt.savefig('shap_overall_importance_lightgbm.png', dpi=300, bbox_inches='tight')
 #plt.show()

# SHAP Feature Importance by Class - æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾é‡è¦æ€§
print("\nSHAP Feature Importance by Class - æ¯ä¸ªç±»åˆ«çš„ç‰¹å¾é‡è¦æ€§")

# ç±»åˆ«æ•°é‡
n_classes = len(class_names_display)
colors = ['steelblue', 'coral', 'lightgreen']  # å¯æ ¹æ®ç±»åˆ«æ•°æ‰©å±•

# åˆ›å»ºå­å›¾
fig, axes = plt.subplots(1, n_classes, figsize=(6*n_classes, 6))

# å¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œaxesä¸æ˜¯æ•°ç»„ï¼Œéœ€è¦å¤„ç†
if n_classes == 1:
    axes = [axes]

for i in range(n_classes):
    # è®¡ç®—è¯¥ç±»åˆ«çš„å¹³å‡ç»å¯¹SHAPå€¼
    class_importance = np.mean(np.abs(shap_values_list[i]), axis=0)
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': class_importance
    }).sort_values('importance', ascending=True)

    axes[i].barh(importance_df['feature'], importance_df['importance'],
                 color=colors[i % len(colors)])
    axes[i].set_title(f'ç±»åˆ« {class_names_display[i]}\nSHAPç‰¹å¾é‡è¦æ€§ - LightGBM',
                      fontsize=12, fontweight='bold')
    axes[i].set_xlabel('å¹³å‡|SHAPå€¼|')

plt.tight_layout()
plt.savefig('shap_importance_by_class_lightgbm.png', dpi=300, bbox_inches='tight')
 #plt.show()


# SHAP Overall Feature Importance - ç»¼åˆç‰¹å¾é‡è¦æ€§
print("\nSHAP Overall Feature Importance - ç»¼åˆç‰¹å¾é‡è¦æ€§")

# ç±»åˆ«æ•°é‡
n_classes = len(shap_values_list)

# è®¡ç®—æ‰€æœ‰ç±»åˆ«çš„å¹³å‡ç‰¹å¾é‡è¦æ€§
overall_importance = np.mean(
    [np.mean(np.abs(shap_values_list[i]), axis=0) for i in range(n_classes)],
    axis=0
)

importance_df = pd.DataFrame({
    'feature': feature_cols,
    'importance': overall_importance
}).sort_values('importance', ascending=True)

plt.figure(figsize=(10, 8))
bars = plt.barh(importance_df['feature'], importance_df['importance'],
                color='steelblue', alpha=0.8)
plt.title('SHAP ç»¼åˆç‰¹å¾é‡è¦æ€§ (æ‰€æœ‰ç±»åˆ«å¹³å‡) - LightGBM',
          fontsize=14, fontweight='bold', pad=20)
plt.xlabel('å¹³å‡|SHAPå€¼|')
plt.grid(axis='x', alpha=0.3)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for i, bar in enumerate(bars):
    width = bar.get_width()
    plt.text(width + width * 0.01, bar.get_y() + bar.get_height() / 2,
             f'{width:.3f}', ha='left', va='center', fontsize=10)

plt.tight_layout()
plt.savefig('shap_overall_importance_lightgbm.png', dpi=300, bbox_inches='tight')
 #plt.show()
